"use strict";(self.webpackChunkpaulohernane_me=self.webpackChunkpaulohernane_me||[]).push([[2455],{3366:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>s,contentTitle:()=>o,default:()=>h,frontMatter:()=>c,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"data-science/machine-learning/machine-learning-and-data-science-course/computer-vision","title":"Computer Vision","description":"Computer vision is a field of artificial intelligence that focuses on enabling computers to interpret and understand the visual world. It involves the development of algorithms and techniques that allow computers to extract information from images or videos.","source":"@site/my-brain/data-science/machine-learning/machine-learning-and-data-science-course/computer-vision.md","sourceDirName":"data-science/machine-learning/machine-learning-and-data-science-course","slug":"/data-science/machine-learning/machine-learning-and-data-science-course/computer-vision","permalink":"/my-brain/data-science/machine-learning/machine-learning-and-data-science-course/computer-vision","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"machine-learning","permalink":"/my-brain/tags/machine-learning"},{"inline":true,"label":"computer-vision","permalink":"/my-brain/tags/computer-vision"},{"inline":true,"label":"image-processing","permalink":"/my-brain/tags/image-processing"},{"inline":true,"label":"deep-learning","permalink":"/my-brain/tags/deep-learning"}],"version":"current","frontMatter":{"id":"computer-vision","title":"Computer Vision","tags":["machine-learning","computer-vision","image-processing","deep-learning"]},"sidebar":"myBrainSidebar","previous":{"title":"svm","permalink":"/my-brain/data-science/machine-learning/machine-learning-and-data-science-course/classification/svm/"},"next":{"title":"Data Pre-processing","permalink":"/my-brain/data-science/machine-learning/machine-learning-and-data-science-course/data-pre-processing/"}}');var t=a(4848),r=a(8453);const c={id:"computer-vision",title:"Computer Vision",tags:["machine-learning","computer-vision","image-processing","deep-learning"]},o=void 0,s={},l=[{value:"Cascade Classifiers",id:"cascade-classifiers",level:3},{value:"FAce Detection",id:"face-detection",level:2},{value:"Face Recognition",id:"face-recognition",level:2},{value:"LBPH (Local Binary Patterns Histograms)",id:"lbph-local-binary-patterns-histograms",level:3},{value:"Object Tracking",id:"object-tracking",level:2},{value:"CSRT (Channel and Spatial Reliability Tracker)",id:"csrt-channel-and-spatial-reliability-tracker",level:3}];function d(e){const n={code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.p,{children:"Computer vision is a field of artificial intelligence that focuses on enabling computers to interpret and understand the visual world. It involves the development of algorithms and techniques that allow computers to extract information from images or videos."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Object and face detection"}),"\n",(0,t.jsx)(n.li,{children:"Face recognition"}),"\n",(0,t.jsx)(n.li,{children:"Object tracking"}),"\n",(0,t.jsx)(n.li,{children:"Image segmentation"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"cascade-classifiers",children:"Cascade Classifiers"}),"\n",(0,t.jsx)(n.p,{children:"To work with Cascade Classifiers to face detection we need to have a dataset with faces and non-faces images."}),"\n",(0,t.jsxs)(n.p,{children:["We need to apply the ",(0,t.jsx)(n.code,{children:"AdaBoost"})," algorithm to select the best features to use in the classifier."]}),"\n",(0,t.jsx)(n.p,{children:"The Classifier is a cascade of weak classifiers that are trained to detect faces."}),"\n",(0,t.jsx)(n.p,{children:"There a lot of pre-trained models available in OpenCV."}),"\n",(0,t.jsx)(n.h2,{id:"face-detection",children:"FAce Detection"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import cv2\n\n# Load the pre-trained model\nface_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n\n# Load the image\nimage = cv2.imread('image.jpg')\n\n# Convert the image to grayscale\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n# Detect faces in the image\nfaces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n\n# Draw rectangles around the faces\nfor (x, y, w, h) in faces:\n    cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)\n\n# Display the image\ncv2.imshow('Faces', image)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n"})}),"\n",(0,t.jsx)(n.h2,{id:"face-recognition",children:"Face Recognition"}),"\n",(0,t.jsx)(n.h3,{id:"lbph-local-binary-patterns-histograms",children:"LBPH (Local Binary Patterns Histograms)"}),"\n",(0,t.jsx)(n.p,{children:"The LBPH algorithm is a texture-based face recognition algorithm that works by extracting local binary patterns from an image and creating a histogram of these patterns."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import cv2\n\n# Load the pre-trained model\nlbph = cv2.face.LBPHFaceRecognizer_create()\n\n# Train the model\nlbph.train(faces, labels)\n\n# Save the model\nlbph.write('lbph_model.xml')\n\n# Load the model\nlpbh = cv2.face.LBPHFaceRecognizer_create()\nlbph.read('lbph_model.xml')\n\n# Predict the label of a face\nlabel, confidence = lbph.predict(face)\n"})}),"\n",(0,t.jsx)(n.h2,{id:"object-tracking",children:"Object Tracking"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"More fast than object detection"}),"\n",(0,t.jsx)(n.li,{children:"The object uses the previous position to predict the next position"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"csrt-channel-and-spatial-reliability-tracker",children:"CSRT (Channel and Spatial Reliability Tracker)"}),"\n",(0,t.jsx)(n.p,{children:"The CSRT algorithm is a robust object tracking algorithm that uses the channel and spatial reliability of the object to track it."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import cv2\n\n# Load the pre-trained model\ntracker = cv2.TrackerCSRT_create()\n\n# Load the video\nvideo = cv2.VideoCapture('video.mp4')\n\n# Read the first frame\nok, frame = video.read()\n\n# Select the object to track\nbbox = cv2.selectROI(frame)\n\n# Initialize the tracker\nok = tracker.init(frame, bbox)\n\n# Track the object in the video\nwhile True:\n  ok, frame = video.read()\n  if not ok:\n    break\n\n  # Update the tracker\n  ok, bbox = tracker.update(frame)\n\n  if ok:\n    # Draw a rectangle around the object\n    (x, y, w, h) = [int(v) for v in bbox]\n    cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n  else:\n    # Tracking failure\n    cv2.putText(frame, 'Tracking failure detected', (100, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n\n  if cv2.waitKey(1) & 0xFF == 27:\n    break\n"})})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,a)=>{a.d(n,{R:()=>c,x:()=>o});var i=a(6540);const t={},r=i.createContext(t);function c(e){const n=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:c(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);