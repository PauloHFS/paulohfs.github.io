"use strict";(self.webpackChunkpaulohernane_me=self.webpackChunkpaulohernane_me||[]).push([[8351],{1824:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>u,frontMatter:()=>r,metadata:()=>s,toc:()=>l});var a=t(4848),i=t(5680);const r={id:"dimensionality-reduction",title:"Dimensionality Reduction",tags:["machine-learning","dimensionality-reduction","feature-selection","feature-extraction"]},o=void 0,s={id:"machine-learning-and-data-science-course/dimensionality-reduction",title:"Dimensionality Reduction",description:"Feature selection X Feature extraction",source:"@site/my-brain/machine-learning-and-data-science-course/dimensionality-reduction.md",sourceDirName:"machine-learning-and-data-science-course",slug:"/machine-learning-and-data-science-course/dimensionality-reduction",permalink:"/my-brain/machine-learning-and-data-science-course/dimensionality-reduction",draft:!1,unlisted:!1,tags:[{label:"machine-learning",permalink:"/my-brain/tags/machine-learning"},{label:"dimensionality-reduction",permalink:"/my-brain/tags/dimensionality-reduction"},{label:"feature-selection",permalink:"/my-brain/tags/feature-selection"},{label:"feature-extraction",permalink:"/my-brain/tags/feature-extraction"}],version:"current",frontMatter:{id:"dimensionality-reduction",title:"Dimensionality Reduction",tags:["machine-learning","dimensionality-reduction","feature-selection","feature-extraction"]},sidebar:"myBrainSidebar",previous:{title:"Variables Types",permalink:"/my-brain/machine-learning-and-data-science-course/data-pre-processing/variables-types"},next:{title:"Feature Engineering and Selection",permalink:"/my-brain/machine-learning-and-data-science-course/feature-engineering-and-selection"}},c={},l=[{value:"Feature selection X Feature extraction",id:"feature-selection-x-feature-extraction",level:2},{value:"PCA",id:"pca",level:2},{value:"Kernel PCA",id:"kernel-pca",level:2},{value:"LDA",id:"lda",level:2}];function d(e){const n={code:"code",h2:"h2",p:"p",pre:"pre",...(0,i.RP)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.h2,{id:"feature-selection-x-feature-extraction",children:"Feature selection X Feature extraction"}),"\n",(0,a.jsx)(n.p,{children:"Feature selection is the process of selecting a subset of the most important features from a dataset."}),"\n",(0,a.jsx)(n.p,{children:"Feature extraction is the process of creating new features from the existing features in a dataset. Dimensionality reduction techniques such as PCA and LDA are examples of feature extraction."}),"\n",(0,a.jsx)(n.p,{children:"Dimensionality Reduction is the process of reducing the number of features in a dataset by selecting a subset of the most important features or by transforming the data into a lower-dimensional space."}),"\n",(0,a.jsx)(n.h2,{id:"pca",children:"PCA"}),"\n",(0,a.jsx)(n.p,{children:"Principal Component Analysis (PCA) is a technique used to reduce the dimensionality of a dataset by transforming the data into a lower-dimensional space while preserving as much variance as possible."}),"\n",(0,a.jsx)(n.p,{children:"PCA works indentifyng the correlation between the features and creating new features that are linear combinations of the original features."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from sklearn.decomposition import PCA\n\n# Create a PCA object\npca = PCA(n_components=6)\n\n# Fit the object to the data and transform the data\nX_pca = pca.fit_transform(X)\n"})}),"\n",(0,a.jsx)(n.h2,{id:"kernel-pca",children:"Kernel PCA"}),"\n",(0,a.jsx)(n.p,{children:"Kernel PCA is an extension of PCA that uses kernel methods to perform non-linear dimensionality reduction."}),"\n",(0,a.jsx)(n.p,{children:"Kernel PCA works by mapping the data into a higher-dimensional space using a kernel function and then performing PCA in the higher-dimensional space."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from sklearn.decomposition import KernelPCA\n\n# Create a KernelPCA object\nkpca = KernelPCA(n_components=6, kernel='rbf')\n\n# Fit the object to the data and transform the data\nX_kpca = kpca.fit_transform(X)\n"})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.code,{children:"kernel='rbf'"})," is the Radial Basis Function (RBF) kernel, which is commonly used in Kernel PCA. This is a non-linear kernel that can capture complex patterns in the data."]}),"\n",(0,a.jsx)(n.h2,{id:"lda",children:"LDA"}),"\n",(0,a.jsx)(n.p,{children:"Linear Discriminant Analysis (LDA) is a technique used to reduce the dimensionality of a dataset by transforming the data into a lower-dimensional space while maximizing the separation between classes."}),"\n",(0,a.jsx)(n.p,{children:"LDA works by finding the directions (linear discriminants) that maximize the separation between classes."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\n# Create a LDA object\nlda = LinearDiscriminantAnalysis(n_components=6)\n\n# Fit the object to the data and transform the data\nX_lda = lda.fit_transform(X, y)\n"})})]})}function u(e={}){const{wrapper:n}={...(0,i.RP)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},5680:(e,n,t)=>{t.d(n,{RP:()=>l});var a=t(6540);function i(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function r(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function o(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?r(Object(t),!0).forEach((function(n){i(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,a,i=function(e,n){if(null==e)return{};var t,a,i={},r=Object.keys(e);for(a=0;a<r.length;a++)t=r[a],n.indexOf(t)>=0||(i[t]=e[t]);return i}(e,n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)t=r[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(i[t]=e[t])}return i}var c=a.createContext({}),l=function(e){var n=a.useContext(c),t=n;return e&&(t="function"==typeof e?e(n):o(o({},n),e)),t},d={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},u=a.forwardRef((function(e,n){var t=e.components,i=e.mdxType,r=e.originalType,c=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),m=l(t),p=i,h=m["".concat(c,".").concat(p)]||m[p]||d[p]||r;return t?a.createElement(h,o(o({ref:n},u),{},{components:t})):a.createElement(h,o({ref:n},u))}));u.displayName="MDXCreateElement"}}]);